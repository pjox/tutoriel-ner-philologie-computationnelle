{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "277b344c-d95d-4e7e-8fd1-aaca5d80ec9d",
   "metadata": {},
   "source": [
    "# Reconnaître les entités nommées\n",
    "## Entraîner le modèle Bi-LSTM-CRF\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pjox/tutoriel-ner-philologie-computationnelle/blob/master/train_ner_lstm.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e01dfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1BpPdP1xDh0ai4Jz71nc8f0IxjboVHokH\n",
      "To: /Users/portizsu/Code/github.com/pjox/tutoriel-ner-philologie-computationnelle/mini_presto.zip\n",
      "100%|████████████████████████████████████████| 166k/166k [00:00<00:00, 22.6MB/s]\n",
      "Archive:  mini_presto.zip\n",
      "   creating: mini_presto/\n",
      "  inflating: mini_presto/dev.conll   \n",
      "  inflating: mini_presto/test.conll  \n",
      "  inflating: mini_presto/train.conll  \n"
     ]
    }
   ],
   "source": [
    "# Nous commençons par importer les bibliothèques nécessaires et par télécharger les fichiers d'entraînement et de test.\n",
    "! pip install flair gdown\n",
    "! gdown https://drive.google.com/uc\\?id\\=1NgRHG94lQNZ37TSWJZQHScMc69U8QJ6Z\n",
    "! unzip mini_presto.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "277b344c-d95d-4e7e-8fd1-aaca5d80ec9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-01 21:25:02,795 Reading data from ftb\n",
      "2021-12-01 21:25:02,796 Train: ftb/ftb6_train.conll\n",
      "2021-12-01 21:25:02,796 Dev: ftb/ftb6_dev.conll\n",
      "2021-12-01 21:25:02,797 Test: ftb/ftb6_test.conll\n"
     ]
    }
   ],
   "source": [
    "# 1. Nous allons maintenant utiliser la bibliothèque flair pour lire les fichiers d'entraînement et de test.\n",
    "from flair.data import Corpus\n",
    "from flair.datasets import ColumnCorpus\n",
    "\n",
    "# definir les colonnes\n",
    "columns = {0: 'text', 3: 'ner'}\n",
    "\n",
    "# c'est le dossier dans lequel sont les fichiers train, test et dev\n",
    "data_folder = 'mini_presto/'\n",
    "\n",
    "# initier un corpus en utilisant le format de colonne, le dossier de données et les noms des fichiers train, dev et test\n",
    "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
    "                              train_file='train.conll',\n",
    "                              test_file='test.conll',\n",
    "                              dev_file='dev.conll')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "403ef4dc-c72f-4dc6-8bee-09259e615b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9881"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9469cf1-f2b1-4871-a11a-553a7d98d4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certes , rien ne dit qu' une seconde motion de censure sur son projet de loi , reprenant l' accord du 10 avril , n' aurait pas été la bonne mais cette probabilité , reconnaissent les socialistes , n' était pas la plus plausible .\n"
     ]
    }
   ],
   "source": [
    "print(corpus.train[0].to_tagged_string('ner'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59de009a-dbd5-4198-ac8e-f3040845a800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-01 20:44:18,795 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4358/4358 [00:00<00:00, 18370.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-01 20:44:19,078 Corpus contains the labels: ner (#166221)\n",
      "2021-12-01 20:44:19,079 Created (for label 'ner') Dictionary with 12 tags: O, B-time, I-time, B-org, I-org, B-loc, I-loc, B-pers, I-pers, B-prod, I-prod, B-comp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary with 12 tags: O, B-time, I-time, B-org, I-org, B-loc, I-loc, B-pers, I-pers, B-prod, I-prod, B-comp\n",
      "2021-12-01 20:44:33,010 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-01 20:44:33,011 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings('fr')\n",
      "    (list_embedding_1): CharacterEmbeddings(\n",
      "      (char_embedding): Embedding(275, 25)\n",
      "      (char_rnn): LSTM(25, 25, bidirectional=True)\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=350, out_features=350, bias=True)\n",
      "  (rnn): LSTM(350, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=14, bias=True)\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2021-12-01 20:44:33,012 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-01 20:44:33,012 Corpus: \"Corpus: 4358 train + 1165 dev + 1012 test sentences\"\n",
      "2021-12-01 20:44:33,012 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-01 20:44:33,013 Parameters:\n",
      "2021-12-01 20:44:33,013  - learning_rate: \"0.1\"\n",
      "2021-12-01 20:44:33,013  - mini_batch_size: \"32\"\n",
      "2021-12-01 20:44:33,013  - patience: \"3\"\n",
      "2021-12-01 20:44:33,014  - anneal_factor: \"0.5\"\n",
      "2021-12-01 20:44:33,014  - max_epochs: \"150\"\n",
      "2021-12-01 20:44:33,014  - shuffle: \"True\"\n",
      "2021-12-01 20:44:33,014  - train_with_dev: \"False\"\n",
      "2021-12-01 20:44:33,015  - batch_growth_annealing: \"False\"\n",
      "2021-12-01 20:44:33,015 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-01 20:44:33,015 Model training base path: \"resources/taggers/ner-lstm-hipe\"\n",
      "2021-12-01 20:44:33,015 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-01 20:44:33,016 Device: cuda:0\n",
      "2021-12-01 20:44:33,016 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-01 20:44:33,016 Embeddings storage mode: cpu\n",
      "2021-12-01 20:44:33,018 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-01 20:44:41,582 epoch 1 - iter 13/137 - loss 0.90904556 - samples/sec: 48.59 - lr: 0.100000\n",
      "2021-12-01 20:44:50,212 epoch 1 - iter 26/137 - loss 0.70670655 - samples/sec: 48.22 - lr: 0.100000\n",
      "2021-12-01 20:44:57,462 epoch 1 - iter 39/137 - loss 0.61653344 - samples/sec: 57.39 - lr: 0.100000\n",
      "2021-12-01 20:45:03,565 epoch 1 - iter 52/137 - loss 0.56671281 - samples/sec: 68.19 - lr: 0.100000\n",
      "2021-12-01 20:45:15,506 epoch 1 - iter 65/137 - loss 0.52516508 - samples/sec: 34.84 - lr: 0.100000\n",
      "2021-12-01 20:45:25,510 epoch 1 - iter 78/137 - loss 0.48743573 - samples/sec: 41.59 - lr: 0.100000\n",
      "2021-12-01 20:45:32,183 epoch 1 - iter 91/137 - loss 0.47149661 - samples/sec: 62.36 - lr: 0.100000\n",
      "2021-12-01 20:45:38,514 epoch 1 - iter 104/137 - loss 0.45287885 - samples/sec: 65.73 - lr: 0.100000\n",
      "2021-12-01 20:45:45,943 epoch 1 - iter 117/137 - loss 0.43320754 - samples/sec: 56.01 - lr: 0.100000\n",
      "2021-12-01 20:45:55,311 epoch 1 - iter 130/137 - loss 0.41312796 - samples/sec: 44.42 - lr: 0.100000\n",
      "2021-12-01 20:45:57,385 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-01 20:45:57,386 EPOCH 1 done: loss 0.4106 - lr 0.1000000\n",
      "2021-12-01 20:46:06,490 DEV : loss 0.2058420479297638 - f1-score (micro avg)  0.3445\n",
      "2021-12-01 20:46:06,589 BAD EPOCHS (no improvement): 0\n",
      "2021-12-01 20:46:06,591 saving best model\n",
      "2021-12-01 20:46:12,621 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-01 20:46:21,517 epoch 2 - iter 13/137 - loss 0.24249206 - samples/sec: 46.77 - lr: 0.100000\n",
      "2021-12-01 20:46:31,028 epoch 2 - iter 26/137 - loss 0.24251481 - samples/sec: 43.75 - lr: 0.100000\n",
      "2021-12-01 20:46:40,403 epoch 2 - iter 39/137 - loss 0.23216850 - samples/sec: 44.38 - lr: 0.100000\n",
      "2021-12-01 20:46:50,484 epoch 2 - iter 52/137 - loss 0.21660554 - samples/sec: 41.28 - lr: 0.100000\n",
      "2021-12-01 20:47:00,543 epoch 2 - iter 65/137 - loss 0.21607486 - samples/sec: 41.38 - lr: 0.100000\n",
      "2021-12-01 20:47:08,617 epoch 2 - iter 78/137 - loss 0.21625276 - samples/sec: 51.54 - lr: 0.100000\n",
      "2021-12-01 20:47:15,914 epoch 2 - iter 91/137 - loss 0.21305202 - samples/sec: 57.03 - lr: 0.100000\n",
      "2021-12-01 20:47:25,955 epoch 2 - iter 104/137 - loss 0.20762042 - samples/sec: 41.44 - lr: 0.100000\n",
      "2021-12-01 20:47:35,196 epoch 2 - iter 117/137 - loss 0.20530931 - samples/sec: 45.03 - lr: 0.100000\n",
      "2021-12-01 20:47:44,541 epoch 2 - iter 130/137 - loss 0.20134020 - samples/sec: 44.53 - lr: 0.100000\n",
      "2021-12-01 20:47:50,312 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-01 20:47:50,312 EPOCH 2 done: loss 0.2013 - lr 0.1000000\n",
      "2021-12-01 20:47:58,745 DEV : loss 0.1529708057641983 - f1-score (micro avg)  0.4075\n",
      "2021-12-01 20:47:58,842 BAD EPOCHS (no improvement): 0\n",
      "2021-12-01 20:47:58,844 saving best model\n",
      "2021-12-01 20:48:04,955 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-01 20:48:13,681 epoch 3 - iter 13/137 - loss 0.17680566 - samples/sec: 47.69 - lr: 0.100000\n",
      "2021-12-01 20:48:19,964 epoch 3 - iter 26/137 - loss 0.17924231 - samples/sec: 66.24 - lr: 0.100000\n",
      "2021-12-01 20:48:30,551 epoch 3 - iter 39/137 - loss 0.17793595 - samples/sec: 39.30 - lr: 0.100000\n",
      "2021-12-01 20:48:40,055 epoch 3 - iter 52/137 - loss 0.16717341 - samples/sec: 43.79 - lr: 0.100000\n",
      "2021-12-01 20:48:50,282 epoch 3 - iter 65/137 - loss 0.16550200 - samples/sec: 40.69 - lr: 0.100000\n",
      "2021-12-01 20:49:01,667 epoch 3 - iter 78/137 - loss 0.16300030 - samples/sec: 36.55 - lr: 0.100000\n",
      "2021-12-01 20:49:10,216 epoch 3 - iter 91/137 - loss 0.16125577 - samples/sec: 48.68 - lr: 0.100000\n",
      "2021-12-01 20:49:20,483 epoch 3 - iter 104/137 - loss 0.15982749 - samples/sec: 40.53 - lr: 0.100000\n",
      "2021-12-01 20:49:31,075 epoch 3 - iter 117/137 - loss 0.16092696 - samples/sec: 39.28 - lr: 0.100000\n",
      "2021-12-01 20:49:41,085 epoch 3 - iter 130/137 - loss 0.15948975 - samples/sec: 41.57 - lr: 0.100000\n",
      "2021-12-01 20:49:44,791 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-01 20:49:44,792 EPOCH 3 done: loss 0.1596 - lr 0.1000000\n",
      "2021-12-01 20:49:53,019 DEV : loss 0.11211998760700226 - f1-score (micro avg)  0.5588\n",
      "2021-12-01 20:49:53,116 BAD EPOCHS (no improvement): 0\n",
      "2021-12-01 20:49:53,117 saving best model\n",
      "2021-12-01 20:50:01,560 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-01 20:50:09,420 epoch 4 - iter 13/137 - loss 0.15805413 - samples/sec: 52.94 - lr: 0.100000\n",
      "2021-12-01 20:50:17,872 epoch 4 - iter 26/137 - loss 0.14903676 - samples/sec: 49.24 - lr: 0.100000\n",
      "2021-12-01 20:50:27,949 epoch 4 - iter 39/137 - loss 0.14670559 - samples/sec: 41.29 - lr: 0.100000\n",
      "2021-12-01 20:50:38,285 epoch 4 - iter 52/137 - loss 0.14172420 - samples/sec: 40.26 - lr: 0.100000\n",
      "2021-12-01 20:50:47,696 epoch 4 - iter 65/137 - loss 0.14240495 - samples/sec: 44.22 - lr: 0.100000\n",
      "2021-12-01 20:50:58,527 epoch 4 - iter 78/137 - loss 0.14193434 - samples/sec: 38.42 - lr: 0.100000\n",
      "2021-12-01 20:51:06,531 epoch 4 - iter 91/137 - loss 0.14036203 - samples/sec: 51.99 - lr: 0.100000\n",
      "2021-12-01 20:51:16,759 epoch 4 - iter 104/137 - loss 0.13774070 - samples/sec: 40.68 - lr: 0.100000\n",
      "2021-12-01 20:51:24,570 epoch 4 - iter 117/137 - loss 0.13856221 - samples/sec: 53.27 - lr: 0.100000\n",
      "2021-12-01 20:51:34,555 epoch 4 - iter 130/137 - loss 0.13985322 - samples/sec: 41.67 - lr: 0.100000\n",
      "2021-12-01 20:51:40,525 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-01 20:51:40,527 EPOCH 4 done: loss 0.1391 - lr 0.1000000\n",
      "2021-12-01 20:51:49,753 DEV : loss 0.10876163095235825 - f1-score (micro avg)  0.6097\n",
      "2021-12-01 20:51:49,849 BAD EPOCHS (no improvement): 0\n",
      "2021-12-01 20:51:49,849 saving best model\n",
      "2021-12-01 20:51:55,887 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-01 20:52:07,956 epoch 5 - iter 13/137 - loss 0.12446579 - samples/sec: 34.48 - lr: 0.100000\n",
      "2021-12-01 20:52:17,755 epoch 5 - iter 26/137 - loss 0.12796575 - samples/sec: 42.47 - lr: 0.100000\n",
      "2021-12-01 20:52:30,637 epoch 5 - iter 39/137 - loss 0.12759251 - samples/sec: 32.30 - lr: 0.100000\n",
      "2021-12-01 20:52:43,387 epoch 5 - iter 52/137 - loss 0.13522142 - samples/sec: 32.63 - lr: 0.100000\n",
      "2021-12-01 20:52:53,533 epoch 5 - iter 65/137 - loss 0.13657324 - samples/sec: 41.02 - lr: 0.100000\n",
      "2021-12-01 20:52:59,710 epoch 5 - iter 78/137 - loss 0.13462599 - samples/sec: 67.38 - lr: 0.100000\n",
      "2021-12-01 20:53:06,104 epoch 5 - iter 91/137 - loss 0.13470910 - samples/sec: 65.10 - lr: 0.100000\n",
      "2021-12-01 20:53:15,189 epoch 5 - iter 104/137 - loss 0.13396978 - samples/sec: 45.80 - lr: 0.100000\n",
      "2021-12-01 20:53:24,010 epoch 5 - iter 117/137 - loss 0.13433033 - samples/sec: 47.18 - lr: 0.100000\n",
      "2021-12-01 20:53:32,162 epoch 5 - iter 130/137 - loss 0.13254140 - samples/sec: 51.06 - lr: 0.100000\n",
      "2021-12-01 20:53:36,561 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-01 20:53:36,562 EPOCH 5 done: loss 0.1321 - lr 0.1000000\n",
      "2021-12-01 20:53:44,854 DEV : loss 0.0921315997838974 - f1-score (micro avg)  0.6494\n",
      "2021-12-01 20:53:44,951 BAD EPOCHS (no improvement): 0\n",
      "2021-12-01 20:53:44,952 saving best model\n",
      "2021-12-01 20:53:51,011 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-01 20:54:01,267 epoch 6 - iter 13/137 - loss 0.12160052 - samples/sec: 40.57 - lr: 0.100000\n",
      "2021-12-01 20:54:08,536 epoch 6 - iter 26/137 - loss 0.12442309 - samples/sec: 57.25 - lr: 0.100000\n",
      "2021-12-01 20:54:16,133 epoch 6 - iter 39/137 - loss 0.12292459 - samples/sec: 54.78 - lr: 0.100000\n",
      "2021-12-01 20:54:25,221 epoch 6 - iter 52/137 - loss 0.12121998 - samples/sec: 45.79 - lr: 0.100000\n",
      "2021-12-01 20:54:36,884 epoch 6 - iter 65/137 - loss 0.11854464 - samples/sec: 35.68 - lr: 0.100000\n",
      "2021-12-01 20:54:48,715 epoch 6 - iter 78/137 - loss 0.11770797 - samples/sec: 35.17 - lr: 0.100000\n",
      "2021-12-01 20:54:56,247 epoch 6 - iter 91/137 - loss 0.11863067 - samples/sec: 55.25 - lr: 0.100000\n",
      "2021-12-01 20:55:07,497 epoch 6 - iter 104/137 - loss 0.11742092 - samples/sec: 36.99 - lr: 0.100000\n",
      "2021-12-01 20:55:16,858 epoch 6 - iter 117/137 - loss 0.11918380 - samples/sec: 44.45 - lr: 0.100000\n",
      "2021-12-01 20:55:25,921 epoch 6 - iter 130/137 - loss 0.11984980 - samples/sec: 45.92 - lr: 0.100000\n",
      "2021-12-01 20:55:31,187 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-01 20:55:31,188 EPOCH 6 done: loss 0.1195 - lr 0.1000000\n",
      "2021-12-01 20:55:39,505 DEV : loss 0.08542801439762115 - f1-score (micro avg)  0.6812\n",
      "2021-12-01 20:55:39,601 BAD EPOCHS (no improvement): 0\n",
      "2021-12-01 20:55:39,621 saving best model\n",
      "2021-12-01 20:55:45,679 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-01 20:55:52,800 epoch 7 - iter 13/137 - loss 0.12623398 - samples/sec: 58.44 - lr: 0.100000\n",
      "2021-12-01 20:56:03,623 epoch 7 - iter 26/137 - loss 0.11490556 - samples/sec: 38.44 - lr: 0.100000\n",
      "2021-12-01 20:56:12,595 epoch 7 - iter 39/137 - loss 0.11173288 - samples/sec: 46.39 - lr: 0.100000\n",
      "2021-12-01 20:56:24,667 epoch 7 - iter 52/137 - loss 0.10737972 - samples/sec: 34.46 - lr: 0.100000\n",
      "2021-12-01 20:56:34,406 epoch 7 - iter 65/137 - loss 0.10411956 - samples/sec: 42.73 - lr: 0.100000\n",
      "2021-12-01 20:56:42,050 epoch 7 - iter 78/137 - loss 0.10473826 - samples/sec: 54.45 - lr: 0.100000\n",
      "2021-12-01 20:56:52,462 epoch 7 - iter 91/137 - loss 0.10604937 - samples/sec: 39.97 - lr: 0.100000\n",
      "2021-12-01 20:57:01,394 epoch 7 - iter 104/137 - loss 0.10601733 - samples/sec: 46.59 - lr: 0.100000\n",
      "2021-12-01 20:57:10,594 epoch 7 - iter 117/137 - loss 0.10718186 - samples/sec: 45.24 - lr: 0.100000\n",
      "2021-12-01 20:57:20,804 epoch 7 - iter 130/137 - loss 0.10907001 - samples/sec: 40.77 - lr: 0.100000\n",
      "2021-12-01 20:57:24,568 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-01 20:57:24,569 EPOCH 7 done: loss 0.1093 - lr 0.1000000\n",
      "2021-12-01 20:57:33,853 DEV : loss 0.07983767241239548 - f1-score (micro avg)  0.6885\n",
      "2021-12-01 20:57:33,953 BAD EPOCHS (no improvement): 0\n",
      "2021-12-01 20:57:33,954 saving best model\n",
      "2021-12-01 20:57:40,006 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-01 20:57:48,992 epoch 8 - iter 13/137 - loss 0.10996402 - samples/sec: 46.31 - lr: 0.100000\n",
      "2021-12-01 20:57:59,203 epoch 8 - iter 26/137 - loss 0.10175384 - samples/sec: 40.76 - lr: 0.100000\n",
      "2021-12-01 20:58:10,741 epoch 8 - iter 39/137 - loss 0.10889353 - samples/sec: 36.06 - lr: 0.100000\n",
      "2021-12-01 20:58:19,524 epoch 8 - iter 52/137 - loss 0.10774264 - samples/sec: 47.38 - lr: 0.100000\n",
      "2021-12-01 20:58:28,848 epoch 8 - iter 65/137 - loss 0.10596889 - samples/sec: 44.63 - lr: 0.100000\n",
      "2021-12-01 20:58:38,558 epoch 8 - iter 78/137 - loss 0.10500878 - samples/sec: 42.87 - lr: 0.100000\n",
      "2021-12-01 20:58:50,924 epoch 8 - iter 91/137 - loss 0.10237291 - samples/sec: 33.65 - lr: 0.100000\n",
      "2021-12-01 20:59:00,185 epoch 8 - iter 104/137 - loss 0.10413262 - samples/sec: 44.94 - lr: 0.100000\n",
      "2021-12-01 20:59:08,655 epoch 8 - iter 117/137 - loss 0.10509079 - samples/sec: 49.13 - lr: 0.100000\n",
      "2021-12-01 20:59:17,042 epoch 8 - iter 130/137 - loss 0.10555466 - samples/sec: 49.62 - lr: 0.100000\n",
      "2021-12-01 20:59:20,502 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-01 20:59:20,503 EPOCH 8 done: loss 0.1056 - lr 0.1000000\n",
      "2021-12-01 20:59:28,817 DEV : loss 0.0733243003487587 - f1-score (micro avg)  0.6941\n",
      "2021-12-01 20:59:28,914 BAD EPOCHS (no improvement): 0\n",
      "2021-12-01 20:59:28,915 saving best model\n",
      "2021-12-01 20:59:34,952 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-01 20:59:46,722 epoch 9 - iter 13/137 - loss 0.09280256 - samples/sec: 35.35 - lr: 0.100000\n",
      "2021-12-01 20:59:55,423 epoch 9 - iter 26/137 - loss 0.09214938 - samples/sec: 47.83 - lr: 0.100000\n",
      "2021-12-01 21:00:04,353 epoch 9 - iter 39/137 - loss 0.08990999 - samples/sec: 46.60 - lr: 0.100000\n",
      "2021-12-01 21:00:14,063 epoch 9 - iter 52/137 - loss 0.08900543 - samples/sec: 42.86 - lr: 0.100000\n",
      "2021-12-01 21:00:22,877 epoch 9 - iter 65/137 - loss 0.09112577 - samples/sec: 47.21 - lr: 0.100000\n",
      "2021-12-01 21:00:32,369 epoch 9 - iter 78/137 - loss 0.09360689 - samples/sec: 43.84 - lr: 0.100000\n",
      "2021-12-01 21:00:44,555 epoch 9 - iter 91/137 - loss 0.09431398 - samples/sec: 34.15 - lr: 0.100000\n",
      "2021-12-01 21:00:47,363 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-01 21:00:47,364 Exiting from training early.\n",
      "2021-12-01 21:00:47,365 Saving model ...\n",
      "2021-12-01 21:00:53,417 Done.\n",
      "2021-12-01 21:00:53,418 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-01 21:00:53,419 loading file resources/taggers/ner-lstm-hipe/best-model.pt\n",
      "2021-12-01 21:01:07,003 0.0\t0.0\t0.0\t0.0\n",
      "2021-12-01 21:01:07,004 \n",
      "Results:\n",
      "- F-score (micro) 0.0\n",
      "- F-score (macro) 0.0\n",
      "- Accuracy 0.0\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         loc     0.0000    0.0000    0.0000         0\n",
      "        pers     0.0000    0.0000    0.0000         0\n",
      "         org     0.0000    0.0000    0.0000         0\n",
      "        time     0.0000    0.0000    0.0000         0\n",
      "        prod     0.0000    0.0000    0.0000         0\n",
      "\n",
      "   micro avg     0.0000    0.0000    0.0000         0\n",
      "   macro avg     0.0000    0.0000    0.0000         0\n",
      "weighted avg     0.0000    0.0000    0.0000         0\n",
      " samples avg     0.0000    0.0000    0.0000         0\n",
      "\n",
      "2021-12-01 21:01:07,005 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.0,\n",
       " 'dev_score_history': [0.34449374747882205,\n",
       "  0.40752602081665334,\n",
       "  0.5587734241908007,\n",
       "  0.6097087378640778,\n",
       "  0.6494417862838916,\n",
       "  0.6812121212121212,\n",
       "  0.6884841000308738,\n",
       "  0.6941071957358602],\n",
       " 'train_loss_history': [0.4105785700807559,\n",
       "  0.201282371233666,\n",
       "  0.15957253540685326,\n",
       "  0.13914452762670315,\n",
       "  0.13207561516787597,\n",
       "  0.11948045687674902,\n",
       "  0.10930764609446897,\n",
       "  0.10562151351311823],\n",
       " 'dev_loss_history': [tensor(0.2058, device='cuda:0'),\n",
       "  tensor(0.1530, device='cuda:0'),\n",
       "  tensor(0.1121, device='cuda:0'),\n",
       "  tensor(0.1088, device='cuda:0'),\n",
       "  tensor(0.0921, device='cuda:0'),\n",
       "  tensor(0.0854, device='cuda:0'),\n",
       "  tensor(0.0798, device='cuda:0'),\n",
       "  tensor(0.0733, device='cuda:0')]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flair.embeddings import WordEmbeddings, FastTextEmbeddings, CharacterEmbeddings, StackedEmbeddings\n",
    "from flair.models import SequenceTagger\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "# 2. quelle étiquette voulons-nous prédire ?\n",
    "label_type = 'ner'\n",
    "\n",
    "# 3. créer le dictionnaire des étiquettes à partir du corpus\n",
    "label_dict = corpus.make_label_dictionary(label_type=label_type)\n",
    "print(label_dict)\n",
    "\n",
    "# 4. initialiser la pile d'embeddings avec FastText et des représentations de caractères\n",
    "embedding_types = [\n",
    "    # classical Fasttext embeddings\n",
    "    WordEmbeddings('fr'),\n",
    "    # character-level features\n",
    "    CharacterEmbeddings(),\n",
    "]\n",
    "\n",
    "embeddings = StackedEmbeddings(embeddings=embedding_types)\n",
    "\n",
    "# 5. initialiser le tagger de séquences\n",
    "tagger = SequenceTagger(hidden_size=256,\n",
    "                        embeddings=embeddings,\n",
    "                        tag_dictionary=label_dict,\n",
    "                        tag_type=label_type,\n",
    "                        use_crf=True)\n",
    "\n",
    "# 6. initialiser l'entraîneur\n",
    "trainer = ModelTrainer(tagger, corpus)\n",
    "\n",
    "# 7. Commencer l'entraînement\n",
    "trainer.train('resources/taggers/ner-lstm-mini-presto',\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=64,\n",
    "              max_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f199559-ef8f-4d80-98c8-01bfc6be7ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "\n",
    "# Charger le modèle fine-tuné\n",
    "tagger = SequenceTagger.load('resources/taggers/ner-lstm-mini-presto/best-model.pt')\n",
    "\n",
    "sentence = Sentence(\"Il étoit gouverneur de Charlemont, qui par la paix deviendra une place très-considérable ; outre cela, il commandoit à Metz.\")\n",
    "\n",
    "# prédire les balises NER\n",
    "tagger.predict(sentence)\n",
    "\n",
    "# imprimer une phrase avec des balises prédites\n",
    "print(sentence.to_tagged_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
